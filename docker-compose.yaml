services:
  backend:
    container_name: backend
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "80:80" # Port that the HoneyPot listens to and responds on.
      - "8080:8080" # Stats server API port
    restart: always
    environment:
      TZ: Australia/Brisbane
      LLM_URL: "http://llm-cpuonly:5000" # Change this to the service name you've picked
    networks:
      - pandorasbox-net

  # llm-cuda:
  #   container_name: llm-cuda
  #   build:
  #     context: ./llm/model
  #     dockerfile: Dockerfile.nvd
  #   networks:
  #     - pandorasbox-net
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities: [gpu]
  #   environment:
  #     TZ: Australia/Brisbane
  #   restart: always

  llm-cpuonly:
    container_name: llm-cpuonly
    build:
      context: ./llm/model
      dockerfile: Dockerfile.cpu
    networks:
      - pandorasbox-net
    environment:
      TZ: Australia/Brisbane
    restart: always

  # llm-rocm:
  #   container_name: llm-rocm
  #   build:
  #     context: ./llm/model
  #     dockerfile: Dockerfile.amd
  #   environment:
  #     TZ: Australia/Brisbane
  #   restart: always
  #   devices:
  #     - /dev/kfd
  #     - /dev/dri
  #   group_add:
  #     - video
  #   networks:
  #     - pandorasbox-net

  website:
    container_name: website
    build:
      context: ./website
      dockerfile: Dockerfile
    ports:
      - "3000:3000" # Dashboard port
    depends_on:
      - backend
    environment:
      TZ: Australia/Brisbane
    restart: always

networks:
  pandorasbox-net:
    driver: bridge
